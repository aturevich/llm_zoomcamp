{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from rest_api import RESTAPIConfig, rest_api_source\n",
    "from dlt.sources.helpers.rest_client.paginators import BasePaginator, JSONResponsePaginator\n",
    "from dlt.sources.helpers.requests import Response, Request\n",
    "from dlt.destinations.adapters import lancedb_adapter\n",
    "from datetime import datetime, timezone\n",
    "import os\n",
    "import lancedb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SOURCES__REST_API__NOTION__API_KEY\"] = \"\"\n",
    "os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL_PROVIDER\"] = \"sentence-transformers\"\n",
    "os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL\"] = \"all-MiniLM-L6-v2\"\n",
    "os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__URI\"] = \".lancedb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostBodyPaginator(BasePaginator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cursor = None\n",
    "\n",
    "    def update_state(self, response: Response) -> None:\n",
    "        if not response.json():\n",
    "            self._has_next_page = False\n",
    "        else:\n",
    "            self.cursor = response.json().get(\"next_cursor\")\n",
    "            if self.cursor is None:\n",
    "                self._has_next_page = False\n",
    "\n",
    "    def update_request(self, request: Request) -> None:\n",
    "        if request.json is None:\n",
    "            request.json = {}\n",
    "        request.json[\"start_cursor\"] = self.cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.resource(name=\"employee_handbook\")\n",
    "def rest_api_notion_resource():\n",
    "    notion_config: RESTAPIConfig = {\n",
    "        \"client\": {\n",
    "            \"base_url\": \"https://api.notion.com/v1/\",\n",
    "            \"auth\": {\n",
    "                \"token\": dlt.secrets[\"sources.rest_api.notion.api_key\"]\n",
    "            },\n",
    "            \"headers\":{\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Notion-Version\": \"2022-06-28\"\n",
    "            }\n",
    "        },\n",
    "        \"resources\": [\n",
    "            {\n",
    "                \"name\": \"search\",\n",
    "                \"endpoint\": {\n",
    "                    \"path\": \"search\",\n",
    "                    \"method\": \"POST\",\n",
    "                    \"paginator\": PostBodyPaginator(),\n",
    "                    \"json\": {\n",
    "                        \"query\": \"Homework: Employee handbook\",\n",
    "                        \"sort\": {\n",
    "                            \"direction\": \"ascending\",\n",
    "                            \"timestamp\": \"last_edited_time\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"data_selector\": \"results\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"page_content\",\n",
    "                \"endpoint\": {\n",
    "                    \"path\": \"blocks/{page_id}/children\",\n",
    "                    \"paginator\": JSONResponsePaginator(),\n",
    "                    \"params\": {\n",
    "                        \"page_id\": {\n",
    "                            \"type\": \"resolve\",\n",
    "                            \"resource\": \"search\",\n",
    "                            \"field\": \"id\"\n",
    "                        }\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    yield from rest_api_source(notion_config, name=\"employee_handbook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_content(response):\n",
    "    block_id = response[\"id\"]\n",
    "    last_edited_time = response[\"last_edited_time\"]\n",
    "    block_type = response.get(\"type\", \"Not paragraph\")\n",
    "    if block_type != \"paragraph\":\n",
    "        content = \"\"\n",
    "    else:\n",
    "        try:\n",
    "            content = response[\"paragraph\"][\"rich_text\"][0][\"plain_text\"]\n",
    "        except IndexError:\n",
    "            content = \"\"\n",
    "    return {\n",
    "        \"block_id\": block_id,\n",
    "        \"block_type\": block_type,\n",
    "        \"content\": content,\n",
    "        \"last_edited_time\": last_edited_time,\n",
    "        \"inserted_at_time\": datetime.now(timezone.utc)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.resource(\n",
    "    name=\"employee_handbook\",\n",
    "    write_disposition=\"merge\",\n",
    "    primary_key=\"block_id\",\n",
    "    columns={\"last_edited_time\":{\"dedup_sort\":\"desc\"}}\n",
    "    )\n",
    "def rest_api_notion_incremental(\n",
    "    last_edited_time = dlt.sources.incremental(\"last_edited_time\", initial_value=\"2024-06-26T08:16:00.000Z\", primary_key=(\"block_id\"))\n",
    "):\n",
    "    for block in rest_api_notion_resource.add_map(extract_page_content):\n",
    "        if not(len(block[\"content\"])):\n",
    "            continue\n",
    "        yield block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 13:53:41,057|[WARNING]|60837|139992788824064|dlt|logger.py|wrapper:25|The pipeline `run` method will now load the pending load packages. The data you passed to the run function will not be loaded. In order to do that you must run the pipeline again\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homework\n",
      "[{'name': 'block_id', 'nullable': False, 'primary_key': True, 'data_type': 'text'}, {'name': 'block_type', 'data_type': 'text', 'nullable': True}, {'name': 'content', 'x-lancedb-embed': True, 'data_type': 'text', 'nullable': True}, {'dedup_sort': 'desc', 'name': 'last_edited_time', 'data_type': 'timestamp', 'nullable': True}, {'name': 'inserted_at_time', 'data_type': 'timestamp', 'nullable': True}, {'name': '_dlt_load_id', 'data_type': 'text', 'nullable': False}, {'name': '_dlt_id', 'data_type': 'text', 'nullable': False, 'unique': True}]\n",
      "_dlt_loads\n",
      "[{'name': 'load_id', 'data_type': 'text', 'nullable': False}, {'name': 'schema_name', 'data_type': 'text', 'nullable': True}, {'name': 'status', 'data_type': 'bigint', 'nullable': False}, {'name': 'inserted_at', 'data_type': 'timestamp', 'nullable': False}, {'name': 'schema_version_hash', 'data_type': 'text', 'nullable': True}]\n",
      "_dlt_pipeline_state\n",
      "[{'name': 'version', 'data_type': 'bigint', 'nullable': False}, {'name': 'engine_version', 'data_type': 'bigint', 'nullable': False}, {'name': 'pipeline_name', 'data_type': 'text', 'nullable': False}, {'name': 'state', 'data_type': 'text', 'nullable': False}, {'name': 'created_at', 'data_type': 'timestamp', 'nullable': False}, {'name': 'version_hash', 'data_type': 'text', 'nullable': True}, {'name': '_dlt_load_id', 'data_type': 'text', 'nullable': False}, {'name': '_dlt_id', 'data_type': 'text', 'nullable': False, 'unique': True}]\n",
      "_dlt_version\n",
      "[{'name': 'version', 'data_type': 'bigint', 'nullable': False}, {'name': 'engine_version', 'data_type': 'bigint', 'nullable': False}, {'name': 'inserted_at', 'data_type': 'timestamp', 'nullable': False}, {'name': 'schema_name', 'data_type': 'text', 'nullable': False}, {'name': 'version_hash', 'data_type': 'text', 'nullable': False}, {'name': 'schema', 'data_type': 'text', 'nullable': False}]\n",
      "UPLOAD\n",
      "Pipeline company_policies load step completed in 21.10 seconds\n",
      "1 load package(s) were loaded to destination LanceDB and into dataset notion_pages\n",
      "The LanceDB destination used <dlt.destinations.impl.lancedb.configuration.LanceDBCredentials object at 0x7f51faed8190> location to store data\n",
      "Load package 1721119681.4809904 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "def load_notion() -> None:\n",
    "    pipeline = dlt.pipeline(\n",
    "        pipeline_name=\"company_policies\",\n",
    "        destination=\"lancedb\",\n",
    "        dataset_name=\"notion_pages\",\n",
    "    )\n",
    "\n",
    "    load_info = pipeline.run(\n",
    "        lancedb_adapter(\n",
    "            rest_api_notion_incremental,\n",
    "            embed=\"content\"\n",
    "        ),\n",
    "        table_name=\"homework\",\n",
    "        write_disposition=\"merge\"\n",
    "    )\n",
    "    print(load_info)\n",
    "\n",
    "# Run the pipeline\n",
    "load_notion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'notion_pages___homework' table has 17 rows.\n"
     ]
    }
   ],
   "source": [
    "db = lancedb.connect(\".lancedb\")\n",
    "dbtable = db.open_table(\"notion_pages___homework\")\n",
    "\n",
    "row_count = len(dbtable.to_pandas())\n",
    "print(f\"The 'notion_pages___homework' table has {row_count} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stored value for last_edited_time after running the pipeline is: 2024-07-05 23:33:00+00:00\n"
     ]
    }
   ],
   "source": [
    "table = db.open_table(\"notion_pages___homework\")\n",
    "\n",
    "df = table.to_pandas()\n",
    "\n",
    "max_last_edited_time = df['last_edited_time'].max()\n",
    "\n",
    "print(f\"The stored value for last_edited_time after running the pipeline is: {max_last_edited_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this section, we are going to be covering information about paid time off: Employees receive 30 days of Paid Time Off (PTO) per year. Your PTO accrual begins the day you join our company and you receive 2.5 days per month. You can take your PTO at any time after your first week with us and you can use time off you haven’t accrued yet. You will earn one additional day per year after your first year with our company, with a cap at 25 days overall. If you want to use PTO, send a request through our HRIS. If your manager or HR approves, you are permitted to take your leave. You do not have to specify a reason for requesting PTO. You cannot transfer any remaining PTO to the next year. We encourage you to use your time off throughout the year. If you leave our company, we may compensate accrued PTO with your final paycheck according to local law. When the law doesn’t have provisions, we will compensate accrued leave to employees who were not terminated for cause.\n",
      "---\n",
      "Our company observes the following holidays: New Year (January 1), International Women’s Day (March 8), Good Friday (late March or April), Easter Monday (late March or April), International Workers’ Day (May 1), End of the Second World War (May 8, 2025), Ascension Day (late April to early June), Whit Monday (May or June), Day of German Unity (October 3), Christmas (December 25), Boxing day (December 26). If a holiday falls on a day when our company doesn’t operate (e.g. Sunday), we will observe that holiday on the closest business day. Our company offers a floating day, which you can take as a holiday any day you choose. If you want to observe a religious holiday that isn’t included in our list, we may allow you to take unpaid time off for that day. Or, you may use your PTO.\n",
      "---\n",
      "These holidays are considered “off-days” for most employees. If you need a team member to work on a holiday, inform them at least three days in advance. If you are a non-exempt employee, you will receive your regular hourly rate with a premium for working on a holiday. If you are an exempt employee, we will grant you an additional day of PTO that you must take within 12 months after that holiday. We will count hours you worked on a holiday to decide whether you are entitled to overtime pay\n",
      "---\n",
      "Losing a loved one is traumatizing. If this happens to you while you work with us, we want to support you and give you time to cope and mourn. For this reason, we offer five days of paid bereavement leave. If you require more time, please use your PTO. Additional unpaid leave may be requested if needed. Employees should inform their supervisor and the Human Resources department as soon as possible to arrange for the leave.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "pto_content = df[df['content'].str.contains('PTO|paid time off|vacation days', case=False, na=False)]\n",
    "\n",
    "for _, row in pto_content.iterrows():\n",
    "    print(row['content'])\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
